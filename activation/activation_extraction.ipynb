{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vgf3011/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vgf3011/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vgf3011/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vgf3011/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vgf3011/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vgf3011/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/vgf3011/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vgf3011/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vgf3011/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vgf3011/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vgf3011/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vgf3011/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re, os, sys, csv, math, operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = '1024x4D-512x3D-256x3D-128x3D-64x2-32x1-1'\n",
    "activation = 'relu'\n",
    "dropouts = [0.8, 0.9, 0.7, 0.8]\n",
    "SEED = 1234567\n",
    "num_input = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(data, architecture, num_labels=1, activation='relu', dropouts=[]):\n",
    "\n",
    "        assert '-' in architecture\n",
    "        archs = architecture.strip().split('-')\n",
    "        net = data\n",
    "        pen_layer = net\n",
    "        prev_layer = net\n",
    "        prev_num_outputs = None\n",
    "        prev_block_num_outputs = None\n",
    "        prev_stub_output = net\n",
    "        for i in range(len(archs)):\n",
    "            arch = archs[i]\n",
    "            if 'x' in arch:\n",
    "                arch = arch.split('x')\n",
    "                num_outputs = int(re.findall(r'\\d+',arch[0])[0])\n",
    "                layers = int(re.findall(r'\\d+',arch[1])[0])\n",
    "                j = 0\n",
    "                aux_layers = re.findall(r'[A-Z]',arch[0])\n",
    "                for l in range(layers):\n",
    "                    if aux_layers and aux_layers[0] == 'B':\n",
    "                        if len(aux_layers)>1 and aux_layers[1]=='A':\n",
    "                            print('adding fully connected layers with %d outputs followed by batch_norm and act' % num_outputs)\n",
    "\n",
    "                            net = Dense(num_outputs, \n",
    "                                        name='fc' + str(i) + '_' + str(j),\n",
    "                                        activation=None)(net)\n",
    "                            net = BatchNormalization(center=True, scale=True, name='fc_bn'+str(i)+'_'+str(j))(net)\n",
    "                            if activation =='relu': net = Activation('relu')(net)\n",
    "                        else:\n",
    "                            print('adding fully connected layers with %d outputs followed by batch_norm' % num_outputs)\n",
    "                            net = Dense(num_outputs,\n",
    "                                        name='fc' + str(i) + '_' + str(j),\n",
    "                                        activation=activation)(net)\n",
    "                            net = BatchNormalization(center=True, scale=True,\n",
    "                                             name='fc_bn' + str(i) + '_' + str(j))(net)\n",
    "\n",
    "                    else:\n",
    "                        print('adding fully connected layers with %d outputs' % num_outputs)\n",
    "\n",
    "                        net = Dense(num_outputs,\n",
    "                                    name='fc' + str(i) + '_' + str(j), \n",
    "                                    activation=activation)(net)\n",
    "\n",
    "                    if 'R' in aux_layers:\n",
    "                        if prev_num_outputs and prev_num_outputs==num_outputs:\n",
    "                            print('adding residual, both sizes are same')\n",
    "\n",
    "                            net = net+prev_layer\n",
    "                        else:\n",
    "                            print('adding residual with fc as the size are different')\n",
    "                            net = net + Dense(num_outputs,\n",
    "                                                name='fc' + str(i) + '_' +'dim_'+ str(j),\n",
    "                                                activation=None)(prev_layer)\n",
    "                    prev_num_outputs = num_outputs\n",
    "                    j += 1\n",
    "                    prev_layer = net\n",
    "                aux_layers_sub = re.findall(r'[A-Z]', arch[1])\n",
    "                if 'R' in aux_layers_sub:\n",
    "                    if prev_block_num_outputs and prev_block_num_outputs == num_outputs:\n",
    "                        print('adding residual to stub, both sizes are same')\n",
    "                        net = net + prev_stub_output\n",
    "                    else:\n",
    "                        print('adding residual to stub with fc as the size are different')\n",
    "                        net = net + Dense(num_outputs,\n",
    "                                         name='fc' + str(i) + '_' + 'stub_dim_' + str(j),\n",
    "                                         activation=None)(prev_stub_output)\n",
    "\n",
    "                if 'D' in aux_layers_sub and (num_labels == 1) and len(dropouts) > i:\n",
    "                    print('adding dropout', dropouts[i])\n",
    "                    net = Dropout(1.-dropouts[i], seed=SEED)(net, training=False)\n",
    "                prev_stub_output = net\n",
    "                prev_block_num_outputs = num_outputs\n",
    "                prev_layer = net\n",
    "\n",
    "            else:\n",
    "                if 'R' in arch:\n",
    "                    act_fun = 'relu'\n",
    "                    print('using ReLU at last layer')  \n",
    "                else:\n",
    "                    act_fun = None\n",
    "                pen_layer = net\n",
    "                print('adding final layer with ' + str(num_labels) + ' output')\n",
    "                net = Dense(num_labels, name='fc' + str(i),\n",
    "                            activation=act_fun)(net)\n",
    "\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding fully connected layers with 1024 outputs\n",
      "adding fully connected layers with 1024 outputs\n",
      "adding fully connected layers with 1024 outputs\n",
      "adding fully connected layers with 1024 outputs\n",
      "adding dropout 0.8\n",
      "adding fully connected layers with 512 outputs\n",
      "adding fully connected layers with 512 outputs\n",
      "adding fully connected layers with 512 outputs\n",
      "adding dropout 0.9\n",
      "adding fully connected layers with 256 outputs\n",
      "adding fully connected layers with 256 outputs\n",
      "adding fully connected layers with 256 outputs\n",
      "adding dropout 0.7\n",
      "adding fully connected layers with 128 outputs\n",
      "adding fully connected layers with 128 outputs\n",
      "adding fully connected layers with 128 outputs\n",
      "adding dropout 0.8\n",
      "adding fully connected layers with 64 outputs\n",
      "adding fully connected layers with 64 outputs\n",
      "adding fully connected layers with 32 outputs\n",
      "adding final layer with 1 output\n",
      "Model: \"ElemNet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "elemental_fractions (InputLa [(None, 86)]              0         \n",
      "_________________________________________________________________\n",
      "fc0_0 (Dense)                (None, 1024)              89088     \n",
      "_________________________________________________________________\n",
      "fc0_1 (Dense)                (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "fc0_2 (Dense)                (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "fc0_3 (Dense)                (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc1_0 (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "fc1_1 (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "fc1_2 (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2_0 (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "fc2_1 (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "fc2_2 (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc3_0 (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "fc3_1 (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "fc3_2 (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "fc4_0 (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "fc4_1 (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "fc5_0 (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,631,361\n",
      "Trainable params: 4,631,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(num_input,), name='elemental_fractions')\n",
    "outputs = define_model(inputs, architecture, dropouts=dropouts)\n",
    "model = Model(inputs=inputs, outputs=outputs, name= 'ElemNet')\n",
    "model.summary(print_fn=lambda x: print(x))\n",
    "\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss=tf.keras.losses.mean_absolute_error, optimizer=adam, metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cn', 'Cf', 'Fm', 'Fr', 'Po', 'Md', 'Ar', 'Rf', 'Ds', 'Hs', 'Rn', 'Db', 'Lr', 'No', 'Am', 'At', 'Ra', 'Bk', 'Sg', 'Es', 'He', 'Bh', 'Mt', 'Cm', 'Rg', 'Ne']\n"
     ]
    }
   ],
   "source": [
    "#Contains 86 elements (Without Noble elements as it does not forms compounds in normal condition)\n",
    "elements = ['H','Li','Be', 'B', 'C', 'N', 'O', 'F', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl',\n",
    "            'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge',\n",
    "            'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd',\n",
    "            'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd',\n",
    "            'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er','Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', \n",
    "            'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu' ]\n",
    "\n",
    "elements_all = ['H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si', \n",
    "                'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni',\n",
    "                'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', \n",
    "                'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe',\n",
    "                'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho',\n",
    "                'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg',\n",
    "                'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np',\n",
    "                'Pu', 'Am', 'Cm', 'Bk', 'Cf', 'Es', 'Fm', 'Md', 'No', 'Lr', 'Rf', 'Db', 'Sg',\n",
    "                'Bh', 'Hs', 'Mt', 'Ds', 'Rg', 'Cn']\n",
    "\n",
    "# Regex to Choose from Element Name, Number and Either of the Brackets\n",
    "token = re.compile('[A-Z][a-z]?|\\d+|[()]')\n",
    "\n",
    "# Create a dictionary with the Name of the Element as Key and No. of elements as Value\n",
    "def count_elements(formula):\n",
    "    tokens = token.findall(str(formula))\n",
    "    stack = [[]]\n",
    "    for t in tokens:\n",
    "        if t.isalpha():\n",
    "            last = [t]\n",
    "            stack[-1].append(t)\n",
    "        elif t.isdigit():\n",
    "             stack[-1].extend(last*(int(t)-1))\n",
    "        elif t == '(':\n",
    "            stack.append([])\n",
    "        elif t == ')':\n",
    "            last = stack.pop()\n",
    "            stack[-1].extend(last)   \n",
    "    return dict(Counter(stack[-1]))\n",
    "\n",
    "#Normalize the Value of the Dictionary\n",
    "def normalize_elements(dictionary):\n",
    "    dic_val = sum(dictionary.values()) \n",
    "    if dic_val == 0:\n",
    "        factor = 0\n",
    "    else:    \n",
    "        factor=1.0/ dic_val  \n",
    "        \n",
    "    for k in dictionary:\n",
    "        dictionary[k] = dictionary[k]*factor\n",
    "    return dictionary\n",
    "\n",
    "def Diff(li1, li2): \n",
    "    return (list(set(li1) - set(li2))) \n",
    "\n",
    "print(Diff(elements_all, elements)) \n",
    "\n",
    "def elemental_fraction(dataframe):\n",
    "    print('The loaded dataset has %d entries'%len(dataframe['pretty_comp']))\n",
    "\n",
    "    compounds = dataframe['pretty_comp']\n",
    "\n",
    "    print('The reduced dataset has %d entries'%len(compounds))\n",
    "    \n",
    "    compounds = [count_elements(x) for x in compounds]\n",
    "    compounds = [normalize_elements(x) for x in compounds]\n",
    "\n",
    "    in_elements = np.zeros(shape=(len(compounds), len(elements)))\n",
    "    comp_no = 0\n",
    "\n",
    "    for compound in compounds:\n",
    "        keys = compound.keys()\n",
    "        for key in keys:\n",
    "            in_elements[comp_no][elements.index(key)] = compound[key]\n",
    "        comp_no+=1  \n",
    "    \n",
    "    data = in_elements\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n"
    ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(557, 273)\n"
     ]
    }
   ],
   "source": [
    "pred = pd.read_csv(r'../../data/sample_data.csv') \n",
    "print(pred.shape)    \n",
    "\n",
    "pred_prop = pred[elements]\n",
    "\n",
    "#train_phy['compound possible'] = train_phy['compound possible'].astype(float)\n",
    "\n",
    "new_x_pred = pred_prop.values\n",
    "\n",
    "new_x_pred = np.asarray(new_x_pred, dtype=np.float)\n",
    "\n",
    "y_pred = pred.pop('delta_e').to_frame()\n",
    "\n",
    "new_y_pred = np.array(y_pred)\n",
    "\n",
    "new_y_pred.shape = (len(new_y_pred),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = tf.keras.models.Model(inputs=model.inputs, outputs=[layer.output for layer in model.layers])\n",
    "features = extractor(new_x_pred)\n",
    "len(features)\n",
    "#composition = pred.pop('composition').to_frame()\n",
    "composition = pred.pop('pretty_comp').to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(features)):\n",
    "    globals()[\"f\" + str(i)] = features[i].numpy()\n",
    "    globals()[\"df\" + str(i)] = pd.DataFrame(data=globals()[\"f\" + str(i)])\n",
    "    globals()[\"ndf\" + str(i)] = pd.concat([composition,globals()[\"df\" + str(i)],y_pred], axis=1)\n",
    "    path = '../data/sample_f{}.csv'.format(i)\n",
    "    globals()[\"ndf\" + str(i)].to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inlayer = [1024, 1024, 1024, 1024, 512, 512, 512, 256, 256, 256, 128, 128, 128, 64, 64, 32]\n",
    "#for i in range(len(features)):\n",
    "#    globals()[\"f\" + str(i)] = features[i].numpy()\n",
    "#    globals()[\"df\" + str(i)] = pd.DataFrame(data=globals()[\"f\" + str(i)])\n",
    "#    globals()[\"ndf\" + str(i)] = pd.concat([composition,globals()[\"df\" + str(i)],y_pred], axis=1)\n",
    "#    path = \"../data/sample_test_set.csv\".format(i+1, inlayer[i])\n",
    "#    globals()[\"ndf\" + str(i)].to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
